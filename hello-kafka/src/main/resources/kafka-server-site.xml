<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>
    <!-- LogSegment生成相关配置：start -->
    <property>
        <!-- 单个LogSegment的最大大小，当一个LogSegment超过该配置，则会创建一个新的LogSegment文件 -->
        <name>log.segment.bytes</name>
        <!-- default: 1073741824 (1 gb) -->
        <value>1073741824</value>
        <description>
            The maximum size of a single log file
        </description>
    </property>

    <property>
        <!-- 单个LogSegment的最大写入时长。假设一个LogSegment一直没有写满log.segment.bytes，那么会一直往这个LogSegment写数据，当往该log file写入的时间超过了该配置，则会强制生成一个新的LogSegment -->
        <name>log.roll.hours</name>
        <!-- default: 168 (7 day) -->
        <value>168</value>
        <description>
            The maximum time before a new log segment is rolled out (in hours), secondary to log.roll.ms property
        </description>
    </property>
    <!-- LogSegment生成相关配置：end -->

    <!-- 索引文件生成相关配置：start -->
    <property>
        <!-- log文件中每写入多少消息量，就向索引文件中插入一条记录。该配置越大，索引文件中写入的数据越稀疏，根据offset查找record时，顺序向下访问的内容越多。该配置越小，索引文件中写入数据越密集，根据offset查询record时，向下顺序读取的内容越少，但索引文件的容量越大。 -->
        <name>log.index.interval.bytes</name>
        <!-- default: 4096(4kb) -->
        <value>4096</value>
        <description>
            The interval with which we add an entry to the offset index
        </description>
    </property>

    <property>
        <!-- 每个索引文件的最大大小，当索引文件超过该配置后，则生成一个新的索引文件 -->
        <name>log.index.size.max.bytes</name>
        <!-- default: 10485760(10mb) -->
        <value>10485760</value>
        <description>
            The maximum size in bytes of the offset index
        </description>
    </property>
    <!-- 索引文件生成相关配置：end -->

    <!-- 日志清理相关配置：start -->
    <property>
        <!-- 日志清理策略，包含日志删除和日志合并 -->
        <name>log.cleanup.policy</name>
        <!-- default: delete -->
        <value>delete</value>
        <description>
            The default cleanup policy for segments beyond the retention window. A comma separated list of valid policies. Valid policies are: "delete" and "compact"
        </description>
    </property>

    <property>
        <!-- 日志删除的检测周期 -->
        <name>log.retention.check.interval.ms</name>
        <!-- default: 300000 (5 minutes) -->
        <value>300000</value>
        <description>
            The frequency in milliseconds that the log cleaner checks whether any log is eligible for deletion
        </description>
    </property>

    <property>
        <!-- LogSegment的最长存活时间（单位：ms） -->
        <name>log.retention.ms</name>
        <!-- default: null -->
        <value></value>
        <description>
            The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
        </description>
    </property>

    <property>
        <!-- LogSegment的最长存活时间（单位：hour），kafka使用LogSegment中最后一个record的timestamp作为该LogSegment的最后修改时间。当当前时间 - 最后修改时间超过该配置后，那么该LogSegment就是可以被删除的了 -->
        <name>log.retention.hours</name>
        <!-- default: 168(7 day) -->
        <value>168</value>
        <description>
            The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property
        </description>
    </property>

    <property>
        <!-- 每个partition中存留的最大的LogSegment的大小总量，当超过该配置后，则从partition中第一个LogSegment开始删除，直至partition中所有LogSegment的大小小于该配置 -->
        <name>log.retention.bytes</name>
        <!-- default: -1 -->
        <value>-1</value>
        <description>
            The maximum size of the log before deleting it
        </description>
    </property>

    <property>
        <!-- 如果启动log.cleanup.policy使用了compact，那么该参数必须要启动才能进行日志合并 -->
        <name>log.cleaner.enable</name>
        <!-- default: true -->
        <value>true</value>
        <description>
            Enable the log cleaner process to run on the server. Should be enabled if using any topics with a cleanup.policy=compact including the internal offsets topic. If disabled those topics will not be compacted and continually grow in size.
        </description>
    </property>

    <property>
        <!-- 当一个LogSegment被标记为需要删除，那么将会在.log文件后增加.deleted文件，并创建一个延迟任务，该任务会在延迟该配置后，将.log文件从文件系统中真正删除 -->
        <name>file.delete.delay.ms</name>
        <!-- default: 60000 (1 minute) -->
        <value>60000</value>
        <description>
            The time to wait before deleting a file from the filesystem
        </description>
    </property>
    <!-- 日志清理相关配置：end -->

    <property>
        <!-- 创建一个新的topic时，如果没有指定分区数，则使用该配置作为默认的分区数 -->
        <name>num.partitions</name>
        <!-- default: 1 -->
        <value>1</value>
        <description>
            The default number of log partitions per topic
        </description>
    </property>

    <property>
        <!-- broker存储日志文件的目录 -->
        <name>log.dir</name>
        <!-- default: /tmp/kafka-logs -->
        <value>/tmp/kafka-logs</value>
        <description>
            The directory in which the log data is kept (supplemental for log.dirs property)
        </description>
    </property>

    <property>
        <!-- broker连接的zookeeper的地址 -->
        <name>zookeeper.connect</name>
        <!-- default: null -->
        <value></value>
        <description>
            Specifies the ZooKeeper connection string in the form hostname:port where host and port are the host and port of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down you can also specify multiple hosts in the form hostname1:port1,hostname2:port2,hostname3:port3.
            The server can also have a ZooKeeper chroot path as part of its ZooKeeper connection string which puts its data under some path in the global ZooKeeper namespace. For example to give a chroot path of /chroot/path you would give the connection string as hostname1:port1,hostname2:port2,hostname3:port3/chroot/path.
        </description>
    </property>

    <property>
        <!-- broker的id，在一个broker集群中，每个broker应该有一个独一无二的id，如果没有给出，则由kafka自己生成 -->
        <name>broker.id</name>
        <!-- default: -1 -->
        <value>-1</value>
        <description>
            The broker id for this server. If unset, a unique broker id will be generated.To avoid conflicts between zookeeper generated broker id's and user configured broker id's, generated broker ids start from reserved.broker.max.id + 1.
        </description>
    </property>

    <property>
        <!-- broker向zookeeper中注册的该broker的连接信息，客户端在连接到broker时，是获取的该地址 -->
        <name>advertised.listeners</name>
        <!-- default: null -->
        <value>PLAINTEXT://kafka-1:9092</value>
        <description>
            Listeners to publish to ZooKeeper for clients to use, if different than the listeners config property. In IaaS environments, this may need to be different from the interface to which the broker binds. If this is not set, the value for listeners will be used. Unlike listeners, it is not valid to advertise the 0.0.0.0 meta-address.
            Also unlike listeners, there can be duplicated ports in this property, so that one listener can be configured to advertise another listener's address. This can be useful in some cases where external load balancers are used.
        </description>
    </property>

    <property>
        <!-- broker实际监听用户请求的网段和地址，PLAINTEXT://0.0.0.0:9092代表监听所有ip向9092端口发起的请求 -->
        <name>listeners</name>
        <!-- default: null -->
        <value>PLAINTEXT://0.0.0.0:9092</value>
        <description>
            Listener List - Comma-separated list of URIs we will listen on and the listener names. If the listener name is not a security protocol, listener.security.protocol.map must also be set.
            Listener names and port numbers must be unique.
            Specify hostname as 0.0.0.0 to bind to all interfaces.
            Leave hostname empty to bind to default interface.
            Examples of legal listener lists:
            PLAINTEXT://myhost:9092,SSL://:9091
            CLIENT://0.0.0.0:9092,REPLICATION://localhost:9093
        </description>
    </property>

    <property>
        <!-- 是否允许自动创建topic，如果客户端subscribe或assign一个不存在的topic，并且请求参数中auto.create.topics.enable=true，那么如果broker端auto.create.topics.enable=true，则可以自动创建topic -->
        <name>auto.create.topics.enable</name>
        <!-- default: true -->
        <value>true</value>
        <description>
            Enable auto creation of topic on the server
        </description>
    </property>

    <property>
        <!-- 允许consumer客户端设置的session.timeout.ms的最小值 -->
        <name>group.min.session.timeout.ms</name>
        <!-- default: 6000 (6 seconds) -->
        <value>6000</value>
        <description>
            The minimum allowed session timeout for registered consumers. Shorter timeouts result in quicker failure detection at the cost of more frequent consumer heartbeating, which can overwhelm broker resources.
        </description>
    </property>

    <property>
        <!-- 允许consumer客户端设置的session.timeout.ms的最大值 -->
        <name>group.max.session.timeout.ms</name>
        <!-- default: 1800000 (30 minutes) -->
        <value>1800000</value>
        <description>
            The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        </description>
    </property>

    <property>
        <!-- follower副本多长时间没有向leader副本发起通讯或同步请求，leader副本就会将该follower从isr中踢出。
             当leader副本收到客户端发来的数据后，follower副本会向leader副本发起数据拉取请求，如果一个follower在同步的过程中挂掉了，在超过该配置的事件后，leader副本就会把该follower副本从isr踢出，进入osr。
             被踢出isr的最大影响是当leader挂掉后，该follower没有机会被选为leader，因为默认只会从isr中选取新的leader。
             但进入osr的follower依然会继续向leader副本同步数据，当他同步的数据和leader副本差不多后，leader副本又会把他重新从osr加入到isr。 -->
        <name>replica.lag.time.max.ms</name>
        <!-- default: 30000 (30 seconds) -->
        <value>30000</value>
        <description>
            If a follower hasn't sent any fetch requests or hasn't consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr
        </description>
    </property>

    <property>
        <!--
            仅在producer发送的请求中ack=-1或all时起作用，此时broker会判断要发送的partition中isr数量是否超过指定该配置。如果超过，则继续处理，如果没有超过，则直接给producer响应一个异常，告诉producer当前partition的isr数量不满足要求，无法进行数据的处理。
            当producer发来的请求中ack=-1，broker端min.insync.replicas=2，broker在处理该请求时:
            a) 如果发现该partition中isr数量<2，就会直接给客户端响应，响应一个NotEnoughReplicas异常，告知客户端当前partition中没有指定数量的isr。
            b) 如果发现该partition中isr数量>=2，就会继续处理该请求，将数据记录到leader副本中，然后等isr中其他follower都同步完了该数据，再给客户端发送响应。此时即使leader副本挂了，还有isr中的其他follower副本记录着这条数据，数据不会丢失。
            因此，下面这些操作联合起来可以极大地保证数据的可靠性（即producer发出的数据不会在broker端丢失）：
            1.producer发送请求中的ack=-1，只有这样才能让producer客户端知道当前发送的数据是彻底被所有isr副本同步了
            2.要发送的topic的副本因子(replicas) > 1，只有这样才能保证一个partition有多个副本
            3.broker端的min.insync.replicas > 1，只有这样才能保证在接收producer发来的数据时，有多个副本(isr)完成了数据的同步
        -->
        <name>min.insync.replicas</name>
        <!-- default: 1 -->
        <value>1</value>
        <description>
            When a producer sets acks to "all" (or "-1"), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).
            When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write.
        </description>
    </property>

    <property>
        <!-- 存储事务相关信息的__transaction_state的分区数，broker部署后就不允许修改了 -->
        <name>transaction.state.log.num.partitions</name>
        <!-- default: 50 -->
        <value>50</value>
        <description>
            The number of partitions for the transaction topic (should not change after deployment).
        </description>
    </property>

    <property>
        <!-- 存储group位点信息相关信息的__consumer_offsets的分区数，broker部署后就不允许修改了 -->
        <name>offsets.topic.num.partitions</name>
        <!-- default: 50 -->
        <value>50</value>
        <description>
            The number of partitions for the offset commit topic (should not change after deployment).
        </description>
    </property>
</configuration>
