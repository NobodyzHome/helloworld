-- zhangsan,emp_1,2024-06-15 13:20:10,1100,20
-- lisi,emp_2,2024-06-15 16:20:10,2000,15
-- wangwu,emp_3,2024-06-15 16:20:10,2200,16
-- zhaoliu,emp_4,2024-06-15 17:20:10,3000,17
-- leilei,emp_5,2024-06-15 19:20:10,3100,18
-- dada,emp_6,2024-06-15 21:20:10,3300,19
-- xixi,emp_7,2024-06-15 22:20:10,3100,18
-- xiaoming,emp_8,2024-06-15 23:20:10,5000,21
-- xiaoli,emp_9,2024-06-15 21:20:10,2300,23

use mydb;
show tables;
drop table mydb.emp_info_routine_load;
create table mydb.emp_info_routine_load(
    emp_no varchar(100),
    dt date,
    emp_name varchar(200),
    age int,
    salary int not null,
    create_tm datetime
)
primary key(emp_no,dt,emp_name)
partition by (dt)
distributed by hash(emp_name)
order by (salary);


create routine load mydb.routine_load_emp_4 on emp_info_routine_load
COLUMNS TERMINATED BY ",",
-- COLUMNS和broker load的()一样，主要是用来指定，当数据源中字段顺序和表结构顺序不一致时，数据源中的字段和表结构中字段的对应关系。
-- 比如数据是这样的【zhangsan,emp_1,2024-06-15 13:20:10,1100,20】，通过COLUMNS (emp_name,emp_no,create_tm,salary,age)指定zhangsan对应emp_name字段，emp_1对应emp_no字段，依次类推
-- 相比broker load，衍生字段可以直接放在COLUMNS里，而不用放在SET语句里
COLUMNS (emp_name,emp_no,create_tm,salary,age,dt=cast(create_tm as date))
PROPERTIES(
    "desired_concurrent_number"="5",
    "format" = "csv"
)
from kafka(
    -- 配置kafka的broker
     "kafka_broker_list" = "kafka-1:9092",
    -- 配置拉取的topic
    "kafka_topic" = "hello_starrocks",
    -- 配置拉取的partition
    "kafka_partitions" = "0,1,2",
    -- 控制读取的位点，目前可选值为：OFFSET_BEGINNING、OFFSET_END、具体offset
    -- 目前不能从group id中获取位点，所以这块不太好。如果一个Routine Load被停止了，再启动一个新的Routine Load任务，只能通过指定位点的方式继续处理，无法自动从group id中获取需要读取的位点。
    -- 因此一个Routine Load不要轻易stop，如果暂时不消费了的话，可以暂停任务，而不是停止任务。
    "property.kafka_default_offsets" = "OFFSET_BEGINNING",
    -- 配置消费kafka的group id
    "property.group.id"="routine_group"
);

# {"creat_time":"2024-06-15 15:20:10","e_salary":3310,"e_name":"qiqi","e_no":"emp_11","e_age":15}
#  {"e_age":19,"e_salary":2100,"creat_time":"2024-06-15 15:20:10","e_name":"toto","e_no":"emp_12"}
#  {"e_age":32,"e_salary":3300,"creat_time":"2024-06-15 16:20:10","e_name":"zhangsan","e_no":"emp_1"}
# {"e_age":21,"e_salary":3300,"creat_time":"2024-06-15 16:20:10","e_name":"wangwu","e_no":"emp_3"}
# {"e_age":19,"e_salary":2100,"creat_time":"2024-06-15 16:30:35","e_name":"lisi","e_no":"emp_2"}
# {"e_age":17,"e_salary":5500,"creat_time":"2024-06-15 16:30:35","e_name":"lisi","e_no":"emp_2"}

create routine load mydb.routine_load_emp_7 on emp_info_routine_load
COLUMNS (emp_name,emp_no,create_tm,salary,age,dt=cast(create_tm as date),__op=if(age>20,1,0))
properties(
    "format"="json",
    -- jsonpaths和COLUMNS中相同位置的映射在一起
    -- jsonpaths=[\"$.e_name\",\"$.e_no\",\"$.creat_time\",\"$.em_salary\",\"$.e_age\"]
    -- columns (emp_name,emp_no,create_tm,salary,age)
    -- 这种情况下，数据中e_name字段的值会赋值到emp_name（都是在第一位），数据中e_no字段的值会赋值到emp_no（都是在第二位），依此类推
    -- 注意：jsonpaths中给出的顺序不需要和数据中json的key的顺序相同，只需要给出的key和数据中的key相同即可
    "jsonpaths"="[\"$.e_name\",\"$.e_no\",\"$.creat_time\",\"$.e_salary\",\"$.e_age\"]"
)
from kafka(
    "kafka_broker_list"="kafka-1:9092",
    "kafka_topic"="hello_starrocks_json",
    "kafka_partitions"="0,1,2,3",
    "property.kafka_default_offsets"="OFFSET_END"
);

show partitions from emp_info_routine_load;

-- 查询指定的routine load job
show routine load for routine_load_emp_7;
-- 查询指定的routine load job下的load task
show routine load  TASK where jobName= 'routine_load_emp_7';

create table mydb.emp_info(
    name varchar(10),
    id int,
    age int,
    register_tm datetime,
    sex varchar(6),
    birthday date
)
duplicate key(name)
partition by date_trunc('day',register_tm)
distributed by hash(age) buckets 2;

# 名次解释
# 1.导入作业：每次通过CREATE ROUTINE LOAD提交的任务，被称之为导入作业routine load job
# 2.导入任务：FE会计算出该job的并行度，每有一个并行度会创建一个导入任务load task，用于从kafka partition中拉取数据，向BE写数据

# 相关参数配置
# job参数【desired_concurrent_number】用来指定该job期望的并行度。实际并行度是由FE进行计算的，计算公式为：Min(desired_concurrent_number,max_routine_load_task_concurrent_num,Kafka Topic的分区数量、存活BE数量)
# FE参数【max_routine_load_task_concurrent_num】用于控制所有routine load job的最大并行度，默认值：5
# FE参数【max_routine_load_batch_size】用于控制每个load task最多数据的数据量大小（单位：Bytes，默认值：4294967296，即4GB）
# FE参数【routine_load_task_consume_second】用于给所有routine load job的每个load task设置最多读取数据的时间（单位：秒，默认值：15）
# FE参数【routine_load_task_timeout_second】用于给所有routine load job的每个load task设置超时时间（单位：秒，默认值：60，即routine_load_task_consume_second * 4）
# job参数【task_consume_second】用于给单独当前routine load job设置load task的读取数据时间
# job参数【task_timeout_second】用于给单独当前routine load job设置load task的超时时间
# job参数【max_batch_interval】用于设置FE调度load task的间隔（单位：秒，范围：5~60，默认：10）。建议取值为导入间隔 10s 以上，否则会因为导入频率过高可能会报错版本数过多。
# job参数【max_batch_rows】设置load task检测错误的数据窗口，错误数据是指 StarRocks 无法解析的数据，比如非法的 JSON。注意：识别数据是否错误是coordinator BE在消费数据时干的。默认值：200000(20w)，实际窗口大小为10 * max_batch_rows，也就是默认是2000000(200w)
# job参数【max_error_number】设置load task检测出错误数据的行数上限，如果在max_batch_rows窗口内，错误的数据量比max_error_number大，则整个load job变为暂停状态。默认值为0，代表不允许有错误的数据。
# job参数【max_filter_ratio】设置load task检测出错误数据占数据窗口的比率（即错误数据量/max_batch_rows），如果错误比率大于max_filter_ratio，则整个load job变为暂停状态。默认值为1，代表该配置不生效。
# 如果同时配置了max_error_number与max_filter_ratio，那么只要错误行数满足其中任一配置，则load task进入暂停状态
# job参数【format】用于指定kafka中数据的格式。取值范围：CSV、JSON 或者 Avro（自 v3.0.1）。默认值：CSV。
# job参数【jsonpaths】在format=json时起作用，用于指定字段的解析顺序，按顺序赋值给column()中对应位置的变量

# 与broker load不同mydb.routine_load_emp_info中routine_load_emp_info是任务名称，运行中的任务不能同名，但是把这个任务stop后，就可以再用这个任务名启动任务。
# 在COLUMNS中定义接收的字段。如果数据是json类型，接收的字段可与要写入的数据表的字段不一致，但一定要与jsonpaths中定义的字段的顺序一致。如果数据是csv类型，那么接收的字段一定要与数据中按逗号分割后的顺序一致。
# 在COLUMNS中也可以定义计算字段，计算字段排在接收字段的后面
# 可以使用where来过滤数据源中的数据
# 在PROPERTIES中配置job参数，在FROM KAFKA中配置kafka的消费参数
CREATE ROUTINE LOAD mydb.routine_load_emp_info ON emp_info
COLUMNS(name,id,age,tm,tmp_sex,birthday=days_sub(curdate(),age),register_tm=tm,sex=if(tmp_sex=1,'男','女')),
where age<=35
PROPERTIES(
    "desired_concurrent_number" = "2",
    "max_filter_ratio" = "0",
    "format"= "json",
    "jsonpaths" = "[\"$.name\",\"$.id\",\"$.age\",\"$.tm\",\"$.sex\"]",
    "task_consume_second" = "20",
    "task_timeout_second" = "80",
    "max_batch_interval" = "50",
    "max_batch_rows" = "200000",
    "max_error_number" = "20",
    "max_filter_ratio" = "0.05"
)
FROM kafka(
    "kafka_broker_list" = "kafka-1:9092",
    "kafka_topic" = "hello_starrocks",
    "kafka_partitions" = "0,1,2",
    "property.kafka_default_offsets" = "OFFSET_BEGINNING"
);

# 查询指定名称的job信息。此时如果job不在运行中，则无法查询到。
# 刚提交任务时的状态。
# +-----+---------------------+-------------------+---------+-------+------+---------+-------+--------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+-----------------+--------------------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+
# |Id   |Name                 |CreateTime         |PauseTime|EndTime|DbName|TableName|State  |DataSourceType|CurrentTaskNum|JobProperties                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |DataSourceProperties                                                                    |CustomProperties                                                         |Statistic                                                                                                                                                                             |Progress                             |TimestampProgress|ReasonOfStateChanged|ErrorLogUrls|TrackingSQL|OtherMsg                                                                                                                                               |LatestSourcePosition                 |
# +-----+---------------------+-------------------+---------+-------+------+---------+-------+--------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+-----------------+--------------------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+
# |11704|routine_load_emp_info|2024-11-08 17:18:02|null     |null   |mydb  |emp_info |RUNNING|KAFKA         |2             |{"partitions":"*","partial_update":"false","columnToColumnExpr":"name,id,age,tm,tmp_sex,birthday=days_sub(curdate(), INTERVAL age DAY),register_tm=tm,sex=if(sex = 1, '男', '女')","maxBatchIntervalS":"10","partial_update_mode":"null","whereExpr":"`age` <= 35","dataFormat":"json","timezone":"Asia/Shanghai","format":"json","log_rejected_record_num":"0","taskTimeoutSecond":"60","json_root":"","maxFilterRatio":"0.0","strict_mode":"false","jsonpaths":"[\"$.name\",\"$.age\",\"$.tm\",\"$.tmp_sex\"]","taskConsumeSecond":"15","desireTaskConcurrentNum":"2","maxErrorNum":"0","strip_outer_array":"false","currentTaskConcurrentNum":"2","maxBatchRows":"200000"}|{"topic":"hello_starrocks","currentKafkaPartitions":"0,1,2","brokerList":"kafka-1:9092"}|{"group.id":"routine_load_emp_info_6d24a344-be00-4846-8873-74730dfa23c6"}|{"receivedBytes":0,"errorRows":0,"committedTaskNum":0,"loadedRows":0,"loadRowsRate":0,"abortedTaskNum":0,"totalRows":0,"unselectedRows":0,"receivedBytesRate":0,"taskExecuteTimeMs":1}|{"0":"10782","1":"10649","2":"10596"}|{}               |                    |            |           |[2024-11-08 17:24:29] [task id: 4ded4b84-8573-4fc8-a815-0efa7653ae66] [txn id: -1] there is no new data in kafka, wait for 10 seconds to schedule again|{"0":"10783","1":"10650","2":"10597"}|
# +-----+---------------------+-------------------+---------+-------+------+---------+-------+--------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+-----------------+--------------------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+
# 运行报错时，通过ReasonOfStateChanged字段可以查看原因
# +-----+---------------------+-------------------+-------------------+-------+------+---------+------+--------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+
# |Id   |Name                 |CreateTime         |PauseTime          |EndTime|DbName|TableName|State |DataSourceType|CurrentTaskNum|JobProperties                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |DataSourceProperties                                                                    |CustomProperties                                                         |Statistic                                                                                                                                                                             |Progress                             |TimestampProgress|ReasonOfStateChanged                                                                                                                                                   |ErrorLogUrls|TrackingSQL|OtherMsg                                                                                                                                               |LatestSourcePosition                 |
# +-----+---------------------+-------------------+-------------------+-------+------+---------+------+--------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+
# |11704|routine_load_emp_info|2024-11-08 17:18:02|2024-11-08 17:26:41|null   |mydb  |emp_info |PAUSED|KAFKA         |0             |{"partitions":"*","partial_update":"false","columnToColumnExpr":"name,id,age,tm,tmp_sex,birthday=days_sub(curdate(), INTERVAL age DAY),register_tm=tm,sex=if(sex = 1, '男', '女')","maxBatchIntervalS":"10","partial_update_mode":"null","whereExpr":"`age` <= 35","dataFormat":"json","timezone":"Asia/Shanghai","format":"json","log_rejected_record_num":"0","taskTimeoutSecond":"60","json_root":"","maxFilterRatio":"0.0","strict_mode":"false","jsonpaths":"[\"$.name\",\"$.age\",\"$.tm\",\"$.tmp_sex\"]","taskConsumeSecond":"15","desireTaskConcurrentNum":"2","maxErrorNum":"0","strip_outer_array":"false","currentTaskConcurrentNum":"2","maxBatchRows":"200000"}|{"topic":"hello_starrocks","currentKafkaPartitions":"0,1,2","brokerList":"kafka-1:9092"}|{"group.id":"routine_load_emp_info_6d24a344-be00-4846-8873-74730dfa23c6"}|{"receivedBytes":0,"errorRows":0,"committedTaskNum":0,"loadedRows":0,"loadRowsRate":0,"abortedTaskNum":0,"totalRows":0,"unselectedRows":0,"receivedBytesRate":0,"taskExecuteTimeMs":1}|{"0":"10782","1":"10649","2":"10596"}|{}               |ErrorReason{errCode = 2, msg='failed to create task: Referenced column 'sex' in expr 'if(`sex` = 1, '男', '女')' can't be found in column list, derived column is 'sex''}|            |           |[2024-11-08 17:26:33] [task id: 4ded4b84-8573-4fc8-a815-0efa7653ae66] [txn id: -1] there is no new data in kafka, wait for 10 seconds to schedule again|{"0":"10786","1":"10650","2":"10600"}|
# +-----+---------------------+-------------------+-------------------+-------+------+---------+------+--------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------+
show routine load for routine_load_emp_info;
# 查询一个load job下的导入任务（load task）
# +------------------------------------+-----+---------+-----+-------------------+-------------------+----------------+-------+----+------------------------------------------------+--------------------------------------------------------------------+
# |TaskId                              |TxnId|TxnStatus|JobId|CreateTime         |LastScheduledTime  |ExecuteStartTime|Timeout|BeId|DataSourceProperties                            |Message                                                             |
# +------------------------------------+-----+---------+-----+-------------------+-------------------+----------------+-------+----+------------------------------------------------+--------------------------------------------------------------------+
# |e197b683-6318-4c69-87a5-ad033f638f31|-1   |UNKNOWN  |11704|2024-11-08 17:18:06|2024-11-08 17:23:45|NULL            |60     |-1  |Progress:{"0":10783,"2":10597},LatestOffset:null|there is no new data in kafka, wait for 10 seconds to schedule again|
# |4ded4b84-8573-4fc8-a815-0efa7653ae66|-1   |UNKNOWN  |11704|2024-11-08 17:18:06|2024-11-08 17:23:47|NULL            |60     |-1  |Progress:{"1":10650},LatestOffset:null          |there is no new data in kafka, wait for 10 seconds to schedule again|
# +------------------------------------+-----+---------+-----+-------------------+-------------------+----------------+-------+----+------------------------------------------------+--------------------------------------------------------------------+
show routine load task where jobname='routine_load_emp_info';
# 查询所有正在运行中的routine load job。注意：此时可以看到暂停的任务。
# +-----+------------------------+-------------------+-------------------+-------+------+-------------------+-------+--------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+-------------------------------------------------------------+-------------------------------------------------------------------+------------+-----------+--------+----------------------------------------+
# |Id   |Name                    |CreateTime         |PauseTime          |EndTime|DbName|TableName          |State  |DataSourceType|CurrentTaskNum|JobProperties                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |DataSourceProperties                                                                    |CustomProperties                                                                                                    |Statistic                                                                                                                                                                                                                  |Progress                                |TimestampProgress                                            |ReasonOfStateChanged                                               |ErrorLogUrls|TrackingSQL|OtherMsg|LatestSourcePosition                    |
# +-----+------------------------+-------------------+-------------------+-------+------+-------------------+-------+--------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+-------------------------------------------------------------+-------------------------------------------------------------------+------------+-----------+--------+----------------------------------------+
# |12111|load_emp_info_sex_report|2024-11-09 17:33:21|null               |null   |mydb  |emp_info_sex_report|RUNNING|KAFKA         |3             |{"partitions":"*","partial_update":"false","columnToColumnExpr":"age,sex,age_start=age - mod(age, 10),age_end=age - mod(age, 10) + 10,male_cnt=if(sex = 1, 1, 0),female_cnt=if(sex = 1, 0, 1),all_cnt=1,min_age=age,max_age=age","maxBatchIntervalS":"10","partial_update_mode":"null","whereExpr":"*","dataFormat":"json","timezone":"Asia/Shanghai","format":"json","log_rejected_record_num":"0","taskTimeoutSecond":"60","json_root":"","maxFilterRatio":"1.0","strict_mode":"false","jsonpaths":"[\"$.age\",\"$.sex\"]","taskConsumeSecond":"15","desireTaskConcurrentNum":"5","maxErrorNum":"0","strip_outer_array":"false","currentTaskConcurrentNum":"3","maxBatchRows":"200000"}|{"topic":"hello_starrocks","currentKafkaPartitions":"0,1,2","brokerList":"kafka-1:9092"}|{"kafka_default_offsets":"OFFSET_BEGINNING","group.id":"group_emp_info_sex_report"}                                 |{"receivedBytes":70978806,"errorRows":0,"committedTaskNum":2955,"loadedRows":911183,"loadRowsRate":0,"abortedTaskNum":0,"totalRows":911183,"unselectedRows":0,"receivedBytesRate":25000,"taskExecuteTimeMs":2761718}       |{"0":"303743","1":"304036","2":"303401"}|{"0":"1731157602002","1":"1731157597988","2":"1731157604008"}|                                                                   |            |           |        |{"0":"303743","1":"304078","2":"303401"}|
# |12151|routine_load_emp_info   |2024-11-09 17:44:50|2024-11-09 21:06:36|null   |mydb  |emp_info           |PAUSED |KAFKA         |0             |{"partitions":"*","partial_update":"false","columnToColumnExpr":"name,id,age,tm,tmp_sex,birthday=days_sub(curdate(), INTERVAL age DAY),register_tm=tm,sex=if(tmp_sex = 1, '男', '女')","maxBatchIntervalS":"50","partial_update_mode":"null","whereExpr":"`age` <= 35","dataFormat":"json","timezone":"Asia/Shanghai","format":"json","log_rejected_record_num":"0","taskTimeoutSecond":"80","json_root":"","maxFilterRatio":"0.05","strict_mode":"false","jsonpaths":"[\"$.name\",\"$.id\",\"$.age\",\"$.tm\",\"$.sex\"]","taskConsumeSecond":"20","desireTaskConcurrentNum":"2","maxErrorNum":"20","strip_outer_array":"false","currentTaskConcurrentNum":"2","maxBatchRows":"200000"}   |{"topic":"hello_starrocks","currentKafkaPartitions":"0,1,2","brokerList":"kafka-1:9092"}|{"kafka_default_offsets":"OFFSET_BEGINNING","group.id":"routine_load_emp_info_86c37be5-98f1-42b9-af7f-b12f42e1f744"}|{"receivedBytes":70962421,"errorRows":0,"committedTaskNum":403,"loadedRows":735562,"loadRowsRate":1000,"abortedTaskNum":0,"totalRows":910973,"unselectedRows":175411,"receivedBytesRate":182000,"taskExecuteTimeMs":388531}|{"0":"303711","1":"303900","2":"303359"}|{"0":"1731157593073","1":"1731157550066","2":"1731157593036"}|ErrorReason{errCode = 100, msg='User root pauses routine load job'}|            |           |        |{"0":"303708","1":"303895","2":"303358"}|
# +-----+------------------------+-------------------+-------------------+-------+------+-------------------+-------+--------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+-------------------------------------------------------------+-------------------------------------------------------------------+------------+-----------+--------+----------------------------------------+
show routine load;
# 停止指定的routine load job
STOP ROUTINE LOAD FOR routine_load_emp_info;
# 暂停指定的routine load job
pause routine load for routine_load_emp_info;
# 恢复（取消暂停）指定的routine load job
resume routine load for routine_load_emp_info;


select count(*) from mydb.emp_info;

truncate table mydb.emp_info;

create table mydb.emp_info_sex_report(
    age_start int,
    age_end int,
    male_cnt int sum,
    female_cnt int sum,
    all_cnt int sum,
    min_age int min,
    max_age int max
)
aggregate key(age_start,age_end)
distributed by hash(age_start) buckets 1;

create routine load mydb.load_emp_info_sex_report on emp_info_sex_report
COLUMNS(age,sex,age_start=age-mod(age,10),age_end=age-mod(age,10)+10,male_cnt=if(sex=1,1,0),female_cnt=if(sex=1,0,1),all_cnt=1,min_age=age,max_age=age)
properties(
    "format" = "json",
    "jsonpaths" = "[\"$.age\",\"$.sex\"]"
)
from kafka(
    "kafka_broker_list" = "kafka-1:9092",
    "kafka_topic" = "hello_starrocks",
    "kafka_partitions" = "0,1,2",
    "property.kafka_default_offsets" = "OFFSET_BEGINNING",
    "property.group.id" = "group_emp_info_sex_report"
);

stop routine load for load_emp_info_sex_report;
show routine load for load_emp_info_sex_report;
show routine load task where jobname='load_emp_info_sex_report';

select *,
        round((male_cnt/all_cnt)*100,1) male_rate,
     round((female_cnt/all_cnt)*100,1) female_rate
from mydb.emp_info_sex_report;

select
    *
from mydb.emp_info_sex_report;

truncate table mydb.emp_info_sex_report;

show tables from _statistics_;

select * from _statistics_.table_statistic_v1 where table_name='mydb.hello_world';

